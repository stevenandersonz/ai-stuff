# Prompting LLM - Reasoning about API

The purpose was to prompt Davinci-003 and GPT3.5-turbo in two ways:

- Finding hidden task between inputs and outputs
- Use task to program the LLM at inference and retrieve its outputs

The project involved prompting the LLMs in two ways - first, finding hidden tasks
between inputs and outputs, and second, reprogramming the LLMs to read endpoint data
and output a standardized document for the API (I got an almost valid JSON output).
