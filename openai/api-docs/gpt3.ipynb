{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Load your API key from an environment variable or secret management service\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.get(\"/todos\", (req, res) => {\n",
      "  res.send(Todos);\n",
      "});\n",
      "app.post(\"/todos\", (req, res) => {\n",
      "  const todo = {\n",
      "    title: req.body.title,\n",
      "    description: req.body.description,\n",
      "    completed: false,\n",
      "  };\n",
      "  Todos.push(todo);\n",
      "  res.send(todo);\n",
      "});\n",
      "app.get(\"/todos/:id\", (req, res) => {\n",
      "  let todo = Todos.find((todo) => todo.id === parseInt(req.params.id));\n",
      "  res.send(todo);\n",
      "});\n",
      "app.put(\"/todos/:id\", (req, res) => {\n",
      "  let todo = Todos.find((todo) => todo.id === parseInt(req.params.id));\n",
      "  todo.title = req.body.title;\n",
      "  todo.description = req.body.description;\n",
      "  todo.completed = req.body.completed;\n",
      "  for (let i = 0; i < Todos.length; i++) {\n",
      "    if (Todos[i].id === todo.id) {\n",
      "      Todos[i] = todo;\n",
      "    }\n",
      "  }\n",
      "  res.send(todo);\n",
      "});\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "# find and save endpoints\n",
    "# each endpoint must be surrounded by the following comments\n",
    "# // <START>\n",
    "# endpoint code\n",
    "# // <END>\n",
    "filename = './todo/index.js'\n",
    "command = [\"awk\", '/\\/\\/ <START>/{flag=1;next}/\\/\\/ <END>/{flag=0}flag', filename]\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "with open('endpoints.txt', 'w') as f:\n",
    "    f.write(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_vinci(path):\n",
    "    '''\n",
    "    path: path to prompt file, assumes txt extension\n",
    "    '''\n",
    "    prompt = open(f\"{path}.txt\", \"r\").read()\n",
    "    ret = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0, max_tokens=1000)\n",
    "    with open(f\"{path}.out.vinci003.txt\", 'w') as f:\n",
    "        f.write(ret.choices[0].text)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_turbo(path):\n",
    "    '''\n",
    "    path: path to prompt file. File first Line must be system prompt\n",
    "    '''\n",
    "    prompt = open(f\"{path}.txt\", \"r\").readlines()\n",
    "    ret = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt[0]},\n",
    "        {\"role\": \"user\", \"content\": \"\".join(prompt[1:])},\n",
    "    ]\n",
    "    ) \n",
    "    with open(f\"{path}.out.3.5-turbo.txt\", 'w') as f:\n",
    "        f.write(ret.choices[0].message.content)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\nWrite a description of each of the input-output pairs in the form of an object.\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677993037,\n",
      "  \"id\": \"cmpl-6qavlv25ja1TdDUfb7ZtpGJcKSvF5\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 19,\n",
      "    \"prompt_tokens\": 681,\n",
      "    \"total_tokens\": 700\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"The instruction given to the friend was incomplete, and the output they provided suggests that the missing information was about creating a RESTful API using Node.js and Express to manage a todo list. The friend provided input-output pairs describing the various endpoints that would be used to interact with the API, including their paths, HTTP methods, descriptions, request bodies, and response bodies. Overall, the output suggests that the friend has a good understanding of how to create a RESTful API in Node.js and Express.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677993038,\n",
      "  \"id\": \"chatcmpl-6qavm701d95AENILMHxcRqweHgMxi\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 101,\n",
      "    \"prompt_tokens\": 506,\n",
      "    \"total_tokens\": 607\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# USING DAVINCI and TURBO.3.5 to FIND A Prompt given input output pairs\n",
    "ret = prompt_vinci(\"02.finding-prompt\")\n",
    "print(ret)\n",
    "\n",
    "ret = prompt_turbo(\"02.finding-prompt\")\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\nRoute 1: \\nMethod: GET \\nDescription: Retrieve all todos \\nRequest: /todos \\nResponse: Todos\\n\\nRoute 2: \\nMethod: POST \\nDescription: Create a new todo \\nRequest: /todos \\nResponse: Todo\\n\\nRoute 3: \\nMethod: GET \\nDescription: Retrieve a single todo \\nRequest: /todos/:id \\nResponse: Todo\\n\\nRoute 4: \\nMethod: PUT \\nDescription: Update a single todo \\nRequest: /todos/:id \\nResponse: Todo\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677993246,\n",
      "  \"id\": \"cmpl-6qaz8hbZKTatTDYIp0E4muM4ppPaN\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 140,\n",
      "    \"prompt_tokens\": 367,\n",
      "    \"total_tokens\": 507\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Routes:\\n- GET /todos \\n- POST /todos \\n- GET /todos/:id \\n- PUT /todos/:id \\n\\nRoute Details:\\n- GET /todos: Returns all todos.\\n  - Request: None.\\n  - Response: Array of objects where each object represents a todo.\\n- POST /todos: Adds a new todo.\\n  - Request: JSON object with the following properties: \\n    - title (string): The title of the todo.\\n    - description (string): The description of the todo.\\n    - completed (boolean): The status of completion of the todo.\\n  - Response: JSON object with the same fields as the request showing the added todo.\\n- GET /todos/:id: Returns a specific todo based on the given id.\\n  - Request: Parameter id (number): The id of the todo to be returned.\\n  - Response: JSON object representing the todo associated with the given id.\\n- PUT /todos/:id: Updates the todo with the specified id. \\n  - Request: Parameter id (number): The id of the todo to be updated. JSON object with the fields to be updated\\n    - title (string): The new title of the todo.\\n    - description (string): The new description for the todo.\\n    - completed (boolean): The new status of completion for the todo.\\n  - Response: JSON object with the same fields as the request representing the updated todo.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677993250,\n",
      "  \"id\": \"chatcmpl-6qazC9ajLnuI6CW8w5PwCLT4gMnG9\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 290,\n",
      "    \"prompt_tokens\": 258,\n",
      "    \"total_tokens\": 548\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# USING DAVINCI and TURBO.3.5 to EXECUTE A TASK given a PROMPT \n",
    "ret = prompt_vinci(\"00.prompt\")\n",
    "print(ret)\n",
    "\n",
    "ret = prompt_turbo(\"00.prompt\")\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
